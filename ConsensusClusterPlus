# Objective: In one of my project, I have applied ConsensusClusterPlus to multiomics data for clustering analysis. In this document, I will summarize the process from the very begining of 
# reading in data to the end of results' intepretation.
# Reference:
# Matthew D. Wilkerson1, and D. Neil Hayes, ConsensusClusterPlus: a class discovery tool with confidence assessments and item tracking,Bioinformatics. 2010 Jun 15; 26(12): 1572–1573. 
# ConsensusClusterPlus (Tutorial) https://bioconductor.org/packages/release/bioc/vignettes/ConsensusClusterPlus/inst/doc/ConsensusClusterPlus.pdf

# Brief Introduction
Unsupervised class discovery is a highly useful technique in cancer research, in which the intrinsic groups who share biological characteristics may exist but unknown. Two key questions
need to be answered: how many groups are present in a omics dataset and what is the confidence in the number of groups and group membership. 
Consensus Clustering method is a technique that can privide quantitative and visual stability evidence derived from repeated subsampling and clustering. CC reports a consensus results
of these repetitions which is robust from sampling varibility.

# Input 
The input of ConsensusClusterPlus is a data matrix of p feature for n samples (p*n). For example, it can be p genes expression values for n tumor samples.
# Output
Output is the stability evidence for the number of groups and group assignments. This includes graphs, txt files and logs.
For each k, CM plots depict consensus values on a white to blue colour scale, are ordered by the consensus clustering which is shown as a dendrogram, 
and have items' consensus clusters marked by coloured rectangles between the dendrogram and consensus values (Fig. 1A). 
This new feature of ConsensusClusterPlus enables quick and accurate visualization of cluster boundaries, which are not labelled in CC. 
The purpose of CM plots is to find the ‘cleanest’ cluster partition where items nearly always either cluster together giving a high consensus (dark blue colour) 
or do not cluster together giving a low consensus (white). Empirical cumulative distribution function (CDF) plots display consensus distributions for each k (Fig. 1C). 
The purpose of the CDF plot is to find the k at which the distribution reaches an approximate maximum, which indicates a maximum stability 
and after which divisions are equivalent to random picks rather than true cluster structure.
# Algorithm
The algorithm begins by subsampling a proportion of items and a proportion of features from a data matrix. 
Each subsample is then partitioned into up to k groups by a user-specified clustering algorithm: agglomerative hierarchical clustering, k-means or a custom algorithm. 
This process is repeated for a specified number of repetitions. Pairwise consensus values, defined as ‘the proportion of clustering runs in which two items are [grouped] together’ (Monti et al., 2003), 
are calculated and stored in a consensus matrix (CM) for each k. Then for each k, a final agglomerative hierarchical consensus clustering using distance of 1−consensus values is completed and pruned to k groups, which are called consensus clusters.
# Agglomerative Hierarchical Clustering (AHC) is a clustering (or classification) method which has the following advantages: 
It works from the dissimilarities between the objects to be grouped together. A type of dissimilarity can be suited to the subject studied and the nature of the data.

# Procesures
# Prepare input data
mRNA<-read.delim("./data/Chordoma_rnaseq_batch12_rawcount_batchcorrection_ComBat_seq_logrpkm.txt",header = TRUE,stringsAsFactors = FALSE,check.names = FALSE)
names(mRNA)[109:115] <- c("Chord 100", "Chord 101", "Chord 102","Chord 10e", "Chord 86b", "Chord 98",
                          "Chord 99")
mRNA <- mRNA[,names(mRNA)%in%snf$Chordoma.ID]

# For the purpose of selecting the most informative genes for class detection,we reduce the dataset to the top 5,000 most variable genes, measured by median
# absolute deviation. The choice of 5,000 genes and MAD can be substituted with other statistical variability filters. Users can decide what type of filtering to use or to skip filtering.
mads=apply(mRNA,1,mad)
d=mRNA[rev(order(mads))[1:5000],]
d = sweep(d,1, apply(d,1,median,na.rm=T))

# consnesus clustering #
 we selected 80% item resampling (pItem), 80% gene resampling (pFeature), a maximum evalulated k of 6 so that cluster counts of 2 to 10 are evaluated (maxK), 1000 resamplings (reps), agglomerative hierarchical clustering
algorithm (clusterAlg) upon 1- Pearson correlation distances (distance), gave our output a title (title), and opted to have graphical results written to pdf
files. We also used a specific random seed so that this example is repeatable(seed).
library(ConsensusClusterPlus)
res <- ConsensusClusterPlus(as.matrix(d),maxK=10,reps=1000,pItem=0.8,pFeature=1,
                            title="ICA_JADE21_top.05infor",clusterAlg="hc",distance="pearson",seed=1262118388.71279,plot="pdf",writeTable=TRUE)

# Calculate Cophenetic correlation
cor.list <- vector(mode = "list", length=9)
for(i in 1:length(cor.list)){
    k2 <- res[[i+1]]$consensusMatrix
    d1 <- as.dist(t(k2))
    hc <- hclust(d1, "average")
    #hc<- hclust(d1)
    d2 <- cophenetic(hc)
    cor.list[[i]]<-cor(d1, d2)
}

coph.eff<-unlist(cor.list)
k<-2:10

library(stats)
plot(k,coph.eff,ylab="Cophenetic correlation",xlab="Number of clusters",col="black",pch=19)
lines(k,coph.eff,col="black")

# Generating cluster and item consensus
icl = calcICL(results,title=title,plot="png")
icl[["clusterConsensus"]]
icl[["itemConsensus"]][1:5,]







